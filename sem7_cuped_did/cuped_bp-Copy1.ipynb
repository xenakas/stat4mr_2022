{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a88bbc6",
   "metadata": {},
   "source": [
    "# CUPED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82556bba",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554212bc",
   "metadata": {},
   "source": [
    "Let's assume we are a firm that is testing an **ad campaign** and we are interested in understanding whether it increases revenue or not. We randomly split a set of users into a treatment and control group and we show the ad campaign to the treatment group. Differently from the standard A/B test setting, assume we observe users also before the test.\n",
    "\n",
    "We can now generate the simulated data, using the data generating process `dgp_cuped()` from [`src.dgp`](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/dgp.py). I also import some plotting functions and libraries from [`src.utils`](https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/src/utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78359868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:10.600956Z",
     "start_time": "2022-11-07T11:28:10.575819Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6c717e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:12.461326Z",
     "start_time": "2022-11-07T11:28:10.630834Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "from src.dgp import dgp_cuped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e36d5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:12.525628Z",
     "start_time": "2022-11-07T11:28:12.491268Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>ad_campaign</th>\n",
       "      <th>revenue0</th>\n",
       "      <th>revenue1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315635</td>\n",
       "      <td>8.359304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.977799</td>\n",
       "      <td>7.751485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.693796</td>\n",
       "      <td>9.025253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.827975</td>\n",
       "      <td>8.540667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230095</td>\n",
       "      <td>8.910165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  ad_campaign  revenue0  revenue1\n",
       "0  1            0  5.315635  8.359304\n",
       "1  2            1  2.977799  7.751485\n",
       "2  3            0  4.693796  9.025253\n",
       "3  4            0  5.827975  8.540667\n",
       "4  5            0  5.230095  8.910165"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dgp_cuped().generate_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b39301",
   "metadata": {},
   "source": [
    "We have informations on 1000 individuals indexed by `i` for whom we observe the revenue generated pre and post treatment, `revenue0` and `revenue1` respectively, and whether they have been exposed to the `ad_campaign`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdd00e",
   "metadata": {},
   "source": [
    "### Difference in Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0222035",
   "metadata": {},
   "source": [
    "In randomized experiments or A/B tests, **randomization** allows us to estimate the average treatment effect using a simple difference in means. We can just compare the average outcome post-treatment $Y_1$ (`revenue`) across control and treated units and randomization guarantees that this difference is due to the treatment alone, in expectation.\n",
    "\n",
    "$$\n",
    "\\widehat {ATE}^{simple} = \\bar Y_{t=1, d=1} - \\bar Y_{t=1, d=0}\n",
    "$$\n",
    "\n",
    "Where the bar indicates the average over individuals. In our case, we compute the average revenue post ad campaign in the treatment group, minus the average revenue post ad campaign in the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bd449d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:12.578107Z",
     "start_time": "2022-11-07T11:28:12.567012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7914301325347406"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df.loc[df.ad_campaign==True, 'revenue1']) - np.mean(df.loc[df.ad_campaign==False, 'revenue1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ce127",
   "metadata": {},
   "source": [
    "The estimated treatment effect is 1.79, very close to the **true value** of 2. We can obtain the same estimate by regressing the post-treatment outcome `revenue1` on the treatment indicator `ad_campaign`.\n",
    "\n",
    "$$\n",
    "Y_{i, t=1} = \\alpha + \\beta D_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "Where $\\beta$ is the coefficient of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745ff819",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:12.655628Z",
     "start_time": "2022-11-07T11:28:12.617318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    8.2995</td> <td>    0.211</td> <td>   39.398</td> <td> 0.000</td> <td>    7.881</td> <td>    8.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ad_campaign</th> <td>    1.7914</td> <td>    0.301</td> <td>    5.953</td> <td> 0.000</td> <td>    1.194</td> <td>    2.389</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('revenue1 ~ ad_campaign', data=df).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db480a",
   "metadata": {},
   "source": [
    "This estimator is **unbiased**, which means it delivers the correct estimate, on average. However, it can still be improved: we could **decrease its variance**. Decreasing the variance of an estimator is extremely important since it allows us to \n",
    "\n",
    "- **detect smaller effects**\n",
    "- detect the same effect, but with a **smaller sample size**\n",
    "\n",
    "In general, an estimator with a smaller variance allows us to run tests with higher [**power**](https://en.wikipedia.org/wiki/Power_of_a_test), i.e. ability to detect smaller effects.\n",
    "\n",
    "Can we improve the power of our AB test? Yes, with CUPED (among other methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c65f1",
   "metadata": {},
   "source": [
    "## CUPED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc8fec",
   "metadata": {},
   "source": [
    "The **idea** of CUPED is the following. Suppose you are running an AB test and $Y$ is the outcome of interest (`revenue` in our example) and the binary variable $D$ indicates whether a single individual has been treated or not (`ad_campaign` in our example).\n",
    "\n",
    "Suppose you have access to another random variable $X$ which is **not affected** by the treatment and has known expectation $\\mathbb E[X]$. Then define\n",
    "\n",
    "$$\n",
    "\\hat Y^{cuped}_{1} = \\bar Y_1 - \\theta \\bar X + \\theta \\mathbb E [X]\n",
    "$$\n",
    "\n",
    "where $\\theta$ is a scalar. This estimator is an **unbiased** estimator for $\\mathbb E[Y]$ since in expectation the two last terms cancel out. However, the variance of $\\hat Y^{cuped}_{1}$ is \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Var} \\left( \\hat Y^{cuped}_{1} \\right) &= \\text{Var} \\left( \\bar Y_1 - \\theta \\bar X + \\theta \\mathbb E [X] \\right) = \\newline\n",
    "&= \\text{Var} \\left( Y_1 - \\theta X \\right) / n = \\newline\n",
    "&= \\Big( \\text{Var} (Y_1) + \\theta^2 \\text{Var} (X) - 2 \\theta \\text{Cov} (X,Y) \\Big) / n\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that the variance of $\\hat Y^{cuped}_{1}$ is minimized for \n",
    "\n",
    "$$\n",
    "\\theta^* = \\frac{\\text{Cov} (X,Y)}{\\text{Var} (X)} \n",
    "$$\n",
    "\n",
    "Which is the **OLS** estimator of a linear regression of $Y$ on $X$. Substituting $\\theta^*$ into the formula of the variance of $\\hat Y^{cuped}_{1}$ we obtain\n",
    "\n",
    "$$\n",
    "\\text{Var} \\left( \\hat Y^{cuped}_{1} \\right) = \\text{Var} (\\bar Y) (1 - \\rho^2)\n",
    "$$\n",
    "\n",
    "where $\\rho$ is the **correlation** between $Y$ and $X$. Therefore, the higher the correlation between $Y$ and $X$, the higher the variance reduction of CUPED.\n",
    "\n",
    "We can then **estimate the average treatment effect**as the average difference in the transformed outcome between the control and treatment group.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\widehat {ATE}^{cuped} &= \\hat Y^{cuped}_{1} (D=1) - \\hat Y^{cuped}_{1}(D=0) = \\newline\n",
    "&= \\big( \\bar Y_1 - \\theta \\bar X + \\theta \\mathbb E [X] \\ \\big| \\ D = 1 \\big) - \\big( \\bar Y_1 - \\theta \\bar X + \\theta \\mathbb E [X] \\ \\big| \\ D = 0 \\big) = \\newline\n",
    "&= \\big( \\bar Y_1 - \\theta \\bar X \\ \\big| \\ D = 1 \\big) - \\big( \\bar Y_1 - \\theta \\bar X \\ \\big| \\ D = 0 \\big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note that $\\mathbb E[X]$ cancels out when taking the difference. Therefore, it is sufficient to compute \n",
    "\n",
    "$$\n",
    "\\hat Y_{cuped,1}' = \\bar Y_1 - \\theta \\bar X\n",
    "$$\n",
    "\n",
    "This is not an unbiased estimator of $\\mathbb E[Y]$ but still delivers an unbiased estimator of the average treatment effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f20ef6",
   "metadata": {},
   "source": [
    "### Optimal X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf807d81",
   "metadata": {},
   "source": [
    "What is the **optimal choice** for the control variable $X$?\n",
    "\n",
    "We know that $X$ should have the following **properties**:\n",
    "\n",
    "- not affected by the treatment\n",
    "- as correlated with $Y_1$ as possible\n",
    "\n",
    "The authors of the paper suggest using the **pre-treatment outcome** $Y_{0}$ since it gives the most reduction in variance in practice. \n",
    "\n",
    "Therefore, **in practice**, we can compute the CUPED estimate of the average treatment effect as follows:\n",
    "\n",
    "1. Regress $Y_1$ on $Y_0$ and estimate $\\hat \\theta$\n",
    "2. Compute $\\hat Y^{cuped}_{1} = \\bar Y_1 - \\hat \\theta \\bar Y_0$\n",
    "3. Compute the difference of $\\hat Y^{cuped}_{1}$ between treatment and control group\n",
    "\n",
    "Equivalently, we can compute $\\hat Y^{cuped}_{1}$ at the individual level and then regress it on the treatment dummy variable $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba56a267",
   "metadata": {},
   "source": [
    "### Back To The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615e5a3",
   "metadata": {},
   "source": [
    "Let's compute the CUPED estimate for the treatment effect, one step at the time. First, let's estimate $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8aa96cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:12.751314Z",
     "start_time": "2022-11-07T11:28:12.731199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.145811109141671"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = smf.ols('revenue1 ~ revenue0', data=df).fit().params[1]\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9667a",
   "metadata": {},
   "source": [
    "Now we can compute the transformed outcome $\\hat Y^{cuped}_{1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c0c7949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:13.047108Z",
     "start_time": "2022-11-07T11:28:13.039899Z"
    }
   },
   "outputs": [],
   "source": [
    "df['revenue1_cuped'] = df['revenue1'] - theta * (df['revenue0'] - np.mean(df['revenue0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b1fc8",
   "metadata": {},
   "source": [
    "Lastly, we estimate the treatment effect as a difference in means, with the transformed outcome $\\hat Y^{cuped}_{1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b897e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:13.488531Z",
     "start_time": "2022-11-07T11:28:13.441868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    8.2259</td> <td>    0.143</td> <td>   57.677</td> <td> 0.000</td> <td>    7.943</td> <td>    8.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ad_campaign</th> <td>    1.9415</td> <td>    0.204</td> <td>    9.529</td> <td> 0.000</td> <td>    1.537</td> <td>    2.346</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('revenue1_cuped ~ ad_campaign', data=df).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cdaa98",
   "metadata": {},
   "source": [
    "The standard error is 33% smaller!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d58308",
   "metadata": {},
   "source": [
    "### Equivalent Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f4be1",
   "metadata": {},
   "source": [
    "An alternative but algebraically **equivalent** way of obtaining the CUPED estimate is the folowing\n",
    "\n",
    "1. Regress $Y_1$ on $Y_0$ and compute the residuals $\\tilde Y_1$\n",
    "2. Compute $\\hat Y^{cuped}_{1} = \\tilde Y_1 + \\bar Y_1$\n",
    "3. Compute the difference of $\\hat Y^{cuped}_{1}$ between treatment and control group\n",
    "\n",
    "Step (3) is the same as before but (1) and (2) are different. This procedure is called **partialling out** and the algebraic equivalence is guaranteed by the [Frisch-Waugh-Lowell Theorem](https://towardsdatascience.com/59f801eb3299).\n",
    "\n",
    "Let's check if we indeed obtain the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebeabf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:14.264567Z",
     "start_time": "2022-11-07T11:28:14.235272Z"
    }
   },
   "outputs": [],
   "source": [
    "df['revenue1_tilde'] = smf.ols('revenue1 ~ revenue0', data=df).fit().resid + np.mean(df['revenue1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df389f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:14.437518Z",
     "start_time": "2022-11-07T11:28:14.405799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    8.2259</td> <td>    0.143</td> <td>   57.677</td> <td> 0.000</td> <td>    7.943</td> <td>    8.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ad_campaign</th> <td>    1.9415</td> <td>    0.204</td> <td>    9.529</td> <td> 0.000</td> <td>    1.537</td> <td>    2.346</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('revenue1_tilde ~ ad_campaign', data=df).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c771a6f",
   "metadata": {},
   "source": [
    "Yes! The regression table is exactly identical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e556d2bd",
   "metadata": {},
   "source": [
    "## CUPED vs Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ca203",
   "metadata": {},
   "source": [
    "CUPED seems to be a very powerful procedure but it is remindful of at least a couple of other methods.\n",
    "\n",
    "1. Autoregression or regression with control variables\n",
    "2. [Difference-in-Differences](https://diff.healthpolicydatascience.org/)\n",
    "\n",
    "Are these methods the same or is there a difference? Let's check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe477e",
   "metadata": {},
   "source": [
    "### Autoregression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b195377e",
   "metadata": {},
   "source": [
    "The **first question** that came to my mind when I first saw CUPED was \"*is CUPED just the simple difference with an additional control variable?*\". Or equivalently, is CUPED equivalent to running the following regression\n",
    "\n",
    "$$\n",
    "Y_{i, t=1} = \\alpha + \\beta D_i + \\gamma Y_{i, t=0} + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "and estimating $\\gamma$ via least squares?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "203e92a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:15.673029Z",
     "start_time": "2022-11-07T11:28:15.644413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    1.9939</td> <td>    0.603</td> <td>    3.304</td> <td> 0.001</td> <td>    0.796</td> <td>    3.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>revenue0</th>    <td>    1.2249</td> <td>    0.114</td> <td>   10.755</td> <td> 0.000</td> <td>    0.999</td> <td>    1.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ad_campaign</th> <td>    1.9519</td> <td>    0.205</td> <td>    9.529</td> <td> 0.000</td> <td>    1.545</td> <td>    2.358</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('revenue1 ~ revenue0 + ad_campaign', data=df).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ccff4f",
   "metadata": {},
   "source": [
    "The estimated coefficient is very similar to the one we obtained with CUPED and also the standard error is very close. However, they are not exactly the same. \n",
    "\n",
    "If you are familiar with the [Frisch-Waugh-Lowell Theorem](https://towardsdatascience.com/59f801eb3299), you might wonder why the two procedures are **not equivalent**. The reason is that with CUPED we are partialling out only $Y$, while the FWL theorem holds when we are partialling out either X or both X and Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc818747",
   "metadata": {},
   "source": [
    "### Diff-in-Diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823fb22",
   "metadata": {},
   "source": [
    "The **second question** that came to my mind was \"i*s CUPED just difference-in-differences?*\". [Difference-in-Differences](https://diff.healthpolicydatascience.org/) (or diff-in-diffs, or DiD) is an estimator that computes the treatment effect as a **double-difference** instead of a single one: pre-post and treatment-control instead of just treatment-control. \n",
    "\n",
    "$$\n",
    "\\widehat {ATE}^{DiD} = \\big( \\bar Y_{t=1, d=1} - \\bar Y_{t=1, d=0} \\big) - \\big( \\bar Y_{t=0, d=1} - \\bar Y_{t=0, d=0} \\big)\n",
    "$$\n",
    "\n",
    "This method was initially introduced in the 19th century to estimate the causes of a Cholera epidemic in London. The main advantage of diff-in-diff is that it allows to estimate the average treatment effect also when randomization is not perfect and the treatment and control group are not comparable. The **key assumption** that is needed is that these difference between the treatment and control group is constant over time. By taking a double difference, we difference it out.\n",
    "\n",
    "Let's check how diff-in-diff works empirically. The most common way to compute the diff-in-diff estiamtor is to first reshape the data in a **long format** or **panel format** (one observation is an individual $i$ at time period $t$) and then to regress the outcome $Y$ on the full interaction between the post-treatment dummy $T$ and the treatment dummy $D$.\n",
    "\n",
    "$$\n",
    "Y_{i,t} = \\alpha + \\beta D_i + \\gamma \\mathbb I (t=1) + \\delta D_i * \\mathbb I (t=1) + \\varepsilon_{i,t}\n",
    "$$\n",
    "\n",
    "The estimator of the average treatment effect is the coefficient of the interaction coefficient, $\\delta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "961b582d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:16.431316Z",
     "start_time": "2022-11-07T11:28:16.390314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>t</th>\n",
       "      <th>revenue1_tilde</th>\n",
       "      <th>revenue1_cuped</th>\n",
       "      <th>ad_campaign</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.093744</td>\n",
       "      <td>8.093744</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10.164644</td>\n",
       "      <td>10.164644</td>\n",
       "      <td>1</td>\n",
       "      <td>2.977799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9.472203</td>\n",
       "      <td>9.472203</td>\n",
       "      <td>0</td>\n",
       "      <td>4.693796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7.688063</td>\n",
       "      <td>7.688063</td>\n",
       "      <td>0</td>\n",
       "      <td>5.827975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8.742618</td>\n",
       "      <td>8.742618</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i  t  revenue1_tilde  revenue1_cuped  ad_campaign   revenue\n",
       "0  1  0        8.093744        8.093744            0  5.315635\n",
       "1  2  0       10.164644       10.164644            1  2.977799\n",
       "2  3  0        9.472203        9.472203            0  4.693796\n",
       "3  4  0        7.688063        7.688063            0  5.827975\n",
       "4  5  0        8.742618        8.742618            0  5.230095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = pd.wide_to_long(df, stubnames='revenue', i='i', j='t').reset_index()\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544b224",
   "metadata": {},
   "source": [
    "The long dataset is now indexed by individuals $i$ and time $t$. We can now run the diff-in-diffs regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32b19aba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:16.758431Z",
     "start_time": "2022-11-07T11:28:16.726591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>    5.1481</td> <td>    0.174</td> <td>   29.608</td> <td> 0.000</td> <td>    4.805</td> <td>    5.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>t</th>             <td>    3.1514</td> <td>    0.246</td> <td>   12.816</td> <td> 0.000</td> <td>    2.666</td> <td>    3.636</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ad_campaign</th>   <td>   -0.1310</td> <td>    0.248</td> <td>   -0.527</td> <td> 0.599</td> <td>   -0.621</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>t:ad_campaign</th> <td>    1.9224</td> <td>    0.351</td> <td>    5.473</td> <td> 0.000</td> <td>    1.230</td> <td>    2.615</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('revenue ~ t * ad_campaign', data=df_long).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402d74a",
   "metadata": {},
   "source": [
    "The estimated coefficient is close to the true value, 2, but the standard errors are bigger than the ones obtained with all other methods (0.35 >> 0.2). What did we miss? We didn't **cluster the standard errors**! \n",
    "\n",
    "I won't go in detail here on what standard error clustering means, but the intuition is the following. The `statsmodels` package by default computes the standard errors assuming that outcomes are **independent** across observations. This assumption is unlikely to be true in this setting where we observe individuals over time and we are trying to exploit this information. Clustering allows for **correlation** of the outcome variable within clusters. In our case, it makes sense (even without knowing the data generating process) to cluster the standard errors at the individual levels, allowing the outcome to be correlated over time for an individual $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27817a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:17.178964Z",
     "start_time": "2022-11-07T11:28:17.148065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>    5.1481</td> <td>    0.139</td> <td>   37.056</td> <td> 0.000</td> <td>    4.876</td> <td>    5.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>t</th>             <td>    3.1514</td> <td>    0.128</td> <td>   24.707</td> <td> 0.000</td> <td>    2.901</td> <td>    3.401</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ad_campaign</th>   <td>   -0.1310</td> <td>    0.181</td> <td>   -0.724</td> <td> 0.469</td> <td>   -0.486</td> <td>    0.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>t:ad_campaign</th> <td>    1.9224</td> <td>    0.209</td> <td>    9.208</td> <td> 0.000</td> <td>    1.513</td> <td>    2.332</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols('revenue ~ t * ad_campaign', data=df_long)\\\n",
    "    .fit(cov_type='cluster', cov_kwds={'groups': df_long['i']})\\\n",
    "    .summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096ddaa",
   "metadata": {},
   "source": [
    "Clustering standard errors at the individual level we obtain standard errors that are comparable to the previous estimates ($\\sim 0.2$).\n",
    "\n",
    "Note that diff-in-diffs is **equivalent to CUPED** when we assume the CUPED coefficient $\\theta=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2428aefa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:17.551109Z",
     "start_time": "2022-11-07T11:28:17.524615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    8.2353</td> <td>    0.145</td> <td>   56.756</td> <td> 0.000</td> <td>    7.947</td> <td>    8.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ad_campaign</th> <td>    1.9224</td> <td>    0.207</td> <td>    9.274</td> <td> 0.000</td> <td>    1.511</td> <td>    2.334</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['revenue1_cuped2'] = df['revenue1'] - 1 * (df['revenue0'] - np.mean(df['revenue0']))\n",
    "smf.ols('revenue1_cuped2 ~ ad_campaign', data=df).fit().summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964181fd",
   "metadata": {},
   "source": [
    "Indeed, we obtain the same exact coefficient and almost identical standard errors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4a3f3",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24209912",
   "metadata": {},
   "source": [
    "Which method is better? From what we have seen so far, all methods seem to deliver an accurate estimate, but the simple difference has a larger standard deviation.\n",
    "\n",
    "Let's now compare all the methods we have seen so far via **simulation**. We simulate the data generating process `dgp_cuped()` 1000 times and we save the estimated coefficient of the following methods:\n",
    "\n",
    "1. Simple difference\n",
    "2. Autoregression\n",
    "3. Diff-in-diffs\n",
    "4. CUPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d940d367",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:18.494700Z",
     "start_time": "2022-11-07T11:28:18.476616Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate(dgp, K=300, x='revenue0'):\n",
    "    \n",
    "    # Initialize coefficients\n",
    "    results = pd.DataFrame(columns=['k', 'Estimator', 'Estimate'])\n",
    "    \n",
    "    # Compute coefficients\n",
    "    for k in range(K):\n",
    "        temp = pd.DataFrame({'k': [k] * 4, \n",
    "                             'Estimator': ['1. Diff ', '2. Areg ', '3. DiD  ', '4. CUPED'], \n",
    "                             'Estimate': [0] * 4})\n",
    "        \n",
    "        # Draw data\n",
    "        df = dgp.generate_data(seed=k)\n",
    "\n",
    "        # Single diff\n",
    "        temp['Estimate'][0] = smf.ols('revenue1 ~ ad_campaign', data=df).fit().params[1]\n",
    "        \n",
    "        # Autoregression\n",
    "        temp['Estimate'][1] = smf.ols(f'revenue1 ~ ad_campaign + {x}', data=df).fit().params[1]\n",
    "        \n",
    "        # Double diff\n",
    "        df_long = pd.wide_to_long(df.dropna(), stubnames='revenue', i='i', j='t').reset_index()\n",
    "        temp['Estimate'][2] = smf.ols('revenue ~ ad_campaign * t', data=df_long)\\\n",
    "            .fit(cov_type='cluster', cov_kwds={'groups': df_long['i']}).params[3]\n",
    "        \n",
    "        # Cuped\n",
    "        df['revenue1_tilde'] = smf.ols(f'revenue1 ~ {x}', data=df).fit().resid + np.mean(df['revenue1'])\n",
    "        temp['Estimate'][3] = smf.ols('revenue1_tilde ~ ad_campaign', data=df).fit().params[1]\n",
    "                \n",
    "        # Combine estimates\n",
    "        results = pd.concat((results, temp))\n",
    "    \n",
    "    return results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "145c6092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:52.961848Z",
     "start_time": "2022-11-07T11:28:18.767589Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msimulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdgp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdgp_cuped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36msimulate\u001b[0;34m(dgp, K, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m smf\u001b[38;5;241m.\u001b[39mols(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevenue1 ~ ad_campaign\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39mdf)\u001b[38;5;241m.\u001b[39mfit()\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Autoregression\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstimate\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrevenue1 ~ ad_campaign + \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Double diff\u001b[39;00m\n\u001b[1;32m     22\u001b[0m df_long \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mwide_to_long(df\u001b[38;5;241m.\u001b[39mdropna(), stubnames\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevenue\u001b[39m\u001b[38;5;124m'\u001b[39m, i\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, j\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/statsmodels/base/model.py:200\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# with patsy it's drop or raise. let's raise.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 200\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_formula_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m ((endog, exog), missing_idx, design_info) \u001b[38;5;241m=\u001b[39m tmp\n\u001b[1;32m    203\u001b[0m max_endog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_formula_max_endog\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/statsmodels/formula/formulatools.py:63\u001b[0m, in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_util\u001b[38;5;241m.\u001b[39m_is_using_pandas(Y, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 63\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mdmatrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m         result \u001b[38;5;241m=\u001b[39m dmatrices(formula, Y, depth, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     67\u001b[0m                            NA_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/patsy/highlevel.py:309\u001b[0m, in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    308\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m EvalEnvironment\u001b[38;5;241m.\u001b[39mcapture(eval_env, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m (lhs, rhs) \u001b[38;5;241m=\u001b[39m \u001b[43m_do_highlevel_design\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lhs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is missing required outcome variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/patsy/highlevel.py:167\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    164\u001b[0m design_infos \u001b[38;5;241m=\u001b[39m _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m    165\u001b[0m                                   NA_action)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m design_infos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_design_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesign_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# No builders, but maybe we can still get matrices\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formula_like, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/patsy/build.py:888\u001b[0m, in \u001b[0;36mbuild_design_matrices\u001b[0;34m(design_infos, data, NA_action, return_type, dtype)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m factor_info \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39mitervalues(design_info\u001b[38;5;241m.\u001b[39mfactor_infos):\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m factor_info \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m factor_info_to_values:\n\u001b[0;32m--> 888\u001b[0m         value, is_NA \u001b[38;5;241m=\u001b[39m \u001b[43m_eval_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    889\u001b[0m         factor_info_to_isNAs[factor_info] \u001b[38;5;241m=\u001b[39m is_NA\n\u001b[1;32m    890\u001b[0m         \u001b[38;5;66;03m# value may now be a Series, DataFrame, or ndarray\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/patsy/build.py:80\u001b[0m, in \u001b[0;36m_eval_factor\u001b[0;34m(factor_info, data, NA_action)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m safe_issubdtype(np\u001b[38;5;241m.\u001b[39masarray(result)\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mnumber):\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen evaluating numeric factor \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI got non-numeric data of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m                          \u001b[38;5;241m%\u001b[39m (factor\u001b[38;5;241m.\u001b[39mname(), result\u001b[38;5;241m.\u001b[39mdtype),\n\u001b[1;32m     79\u001b[0m                          factor)\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, \u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_numerical_NA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# returns either a 1d ndarray or a pandas.Series, plus is_NA mask\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m factor_info\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/patsy/missing.py:136\u001b[0m, in \u001b[0;36mNAAction.is_numerical_NA\u001b[0;34m(self, arr)\u001b[0m\n\u001b[1;32m    134\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(arr\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNA_types:\n\u001b[0;32m--> 136\u001b[0m     mask \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(arr)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    138\u001b[0m     mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39many(mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:2101\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   2098\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[1;32m   2099\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   2100\u001b[0m ):\n\u001b[0;32m-> 2101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arraylike.py:369\u001b[0m, in \u001b[0;36marray_ufunc\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# e.g. test_multiindex_get_loc\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_ufunc_with_out\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reconstruct(result)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# e.g. test.series.test_ufunc.test_reduce\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arraylike.py:462\u001b[0m, in \u001b[0;36mdispatch_ufunc_with_out\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m \u001b[43m_assign_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/arraylike.py:472\u001b[0m, in \u001b[0;36m_assign_where\u001b[0;34m(out, result, where)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03mSet a ufunc result into 'out', masking with a 'where' argument if necessary.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# no 'where' arg passed to ufunc\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     out[:] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     np\u001b[38;5;241m.\u001b[39mputmask(out, where, result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:5561\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5557\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mallows_duplicate_labels \u001b[38;5;241m=\u001b[39m allows_duplicate_labels\n\u001b[1;32m   5559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 5561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   5562\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5563\u001b[0m \u001b[38;5;124;03m    After regular attribute access, try looking up the name\u001b[39;00m\n\u001b[1;32m   5564\u001b[0m \u001b[38;5;124;03m    This allows simpler access to columns for interactive use.\u001b[39;00m\n\u001b[1;32m   5565\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   5566\u001b[0m     \u001b[38;5;66;03m# Note: obj.x will always call obj.__getattribute__('x') prior to\u001b[39;00m\n\u001b[1;32m   5567\u001b[0m     \u001b[38;5;66;03m# calling obj.__getattr__('x').\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = simulate(dgp=dgp_cuped())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4577b",
   "metadata": {},
   "source": [
    "Let's plot the distribution of the estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181de02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:52.983499Z",
     "start_time": "2022-11-07T11:28:52.983453Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data=results, x=\"Estimate\", hue=\"Estimator\");\n",
    "plt.axvline(x=2, c='k', ls='--');\n",
    "plt.title('Simulated Distributions');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d992b9",
   "metadata": {},
   "source": [
    "We can also tabulate the simulated mean and standard deviation of each estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81e32b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:52.999886Z",
     "start_time": "2022-11-07T11:28:52.999798Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.groupby('Estimator').agg(mean=(\"Estimate\", \"mean\"), std=(\"Estimate\", \"std\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c3b77",
   "metadata": {},
   "source": [
    "All estimators seem **unbiased**: the average values are all close to the true value of 2. Moreover, all estimators have a very similar standard deviation, apart from the single-difference estimator!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79ee22",
   "metadata": {},
   "source": [
    "### Always Identical?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b29ca97",
   "metadata": {},
   "source": [
    "Are the estimators always identical, or is there some difference among them? \n",
    "\n",
    "We could check many different departures from the original data generating process. For simplicity, I will consider only one here: **imperfect randomization**. Other tweaks of the data generating process that I considered are:\n",
    "\n",
    "- pre-treatment missing values\n",
    "- additional covariates / control variables\n",
    "- multiple pre-treatment periods\n",
    "- heterogeneous treatment effects\n",
    "\n",
    "and combinations of them. However, I found imperfect randomization to be the most informative example.\n",
    "\n",
    "Suppose now that **randomization was not perfect** and two groups are not identical. In particular, if the data generating process is\n",
    "\n",
    "$$\n",
    "Y_{i,t} = \\alpha + \\beta D_i + \\gamma \\mathbb I (t=1) + \\delta D_i * \\mathbb I (t=1) + u_i + \\varepsilon_{i,t}\n",
    "$$\n",
    "\n",
    "assume that $\\beta \\neq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccae8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:53.017884Z",
     "start_time": "2022-11-07T11:28:53.017806Z"
    }
   },
   "outputs": [],
   "source": [
    "results_beta1 = simulate(dgp=dgp_cuped(beta=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624dbaa",
   "metadata": {},
   "source": [
    "Let's plot the distribution of the estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d6cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T11:28:53.037893Z",
     "start_time": "2022-11-07T11:28:53.037835Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(data=results_beta1, x=\"Estimate\", hue=\"Estimator\");\n",
    "plt.axvline(x=2, c='k', ls='--');\n",
    "plt.title('Simulated Distributions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c2a4e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-07T09:36:01.848895Z",
     "start_time": "2022-11-07T09:36:01.837545Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. Diff</th>\n",
       "      <td>2.999626</td>\n",
       "      <td>0.291497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. Areg</th>\n",
       "      <td>1.991508</td>\n",
       "      <td>0.227065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. DiD</th>\n",
       "      <td>1.993494</td>\n",
       "      <td>0.197638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. CUPED</th>\n",
       "      <td>1.577712</td>\n",
       "      <td>0.221448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean       std\n",
       "Estimator                    \n",
       "1. Diff    2.999626  0.291497\n",
       "2. Areg    1.991508  0.227065\n",
       "3. DiD     1.993494  0.197638\n",
       "4. CUPED   1.577712  0.221448"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_beta1.groupby('Estimator').agg(mean=(\"Estimate\", \"mean\"), std=(\"Estimate\", \"std\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751cf7d",
   "metadata": {},
   "source": [
    "With imperfect treatment assignment, both difference-in-differences and autoregression are unbiased for the true treatment effect, however diff-in-diffs is more efficient. Both CUPED and simple difference are **biased** instead. Why?\n",
    "\n",
    "Diff-in-diffs explicily controls for **systematic differences** between treatment and control group that are **constant over time**. This is exactly what this estimator was built for. Autoregression performs some sort of matching on the additional covariate, $Y_{t=0}$, effectively controlling for these systematic differences as well, but less efficiently (if you want to know more, I wrote related posts on control variables [here](https://towardsdatascience.com/b63dc69e3d8c) and [here](https://towardsdatascience.com/58b63d25d2ef)). CUPED controls for persistent heterogeneity at the individual level, but not at the treatment assignment level. Lastly, the simple difference estimator does not control for anything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529929e7",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94c6a1",
   "metadata": {},
   "source": [
    "In this post, I have analyzed an estimator of average treatment effects in AB testing, very popular in the industry: CUPED. The key idea is that, by exploiting pre-treatment data, CUPED can **achieve a lower variance** by controlling for individual-level variation that is persistent over time. We have also seen that CUPED is closely related but not equivalent to autoregression and difference-in-differences. The differences among the methods clearly emerge when we have imperfect randomization.\n",
    "\n",
    "An interesting avenue of future research is what happens when we have **a lot of pre-treatment information**, either in terms of time periods or observable characteristics. Scientists from Meta, [Guo, Coey, Konutgan, Li, Schoener, Goldman (2021)](https://proceedings.neurips.cc/paper/2021/hash/488b084119a1c7a4950f00706ec7ea16-Abstract.html), have analyzed this problem in a very recent paper that exploits machine learning techniques to efficiently use this extra information. This approach is closely related to the [Double/Debiased Machine Learning](https://academic.oup.com/ectj/article/21/1/C1/5056401) literature. If you are interested, I wrote two articles on the topic ([part 1](https://towardsdatascience.com/eb767a59975b) and [part 2](https://towardsdatascience.com/bf990720a0b2)) and I might write more in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d9132",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c616b",
   "metadata": {},
   "source": [
    "[1] A. Deng, Y. Xu, R. Kohavi, T. Walker, [Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data](https://dl.acm.org/doi/abs/10.1145/2433396.2433413) (2013), *WSDM*.\n",
    "\n",
    "[2] H. Xir, J. Aurisset, [Improving the sensitivity of online controlled experiments: Case studies at Netflix](https://dl.acm.org/doi/abs/10.1145/2939672.2939733) (2013), *ACM SIGKDD*.\n",
    "\n",
    "[3] Y. Guo, D. Coey, M. Konutgan, W. Li, C. Schoener, M. Goldman, [Machine Learning for Variance Reduction in Online Experiments](https://proceedings.neurips.cc/paper/2021/hash/488b084119a1c7a4950f00706ec7ea16-Abstract.html) (2021), *NeurIPS*.\n",
    "\n",
    "[4] V. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, W. Newey, J. Robins, [Double/debiased machine learning for treatment and structural parameters](https://academic.oup.com/ectj/article/21/1/C1/5056401) (2018), *The Econometrics Journal*.\n",
    "\n",
    "[5] M. Bertrand, E. Duflo, S. Mullainathan, [How Much Should We Trust Differences-In-Differences Estimates?](https://academic.oup.com/qje/article/119/1/249/1876068) (2012), *The Quarterly Journal of Economics*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf96361",
   "metadata": {},
   "source": [
    "### Related Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02cecae",
   "metadata": {},
   "source": [
    "- [Double Debiased Machine Learning (part 1)](https://towardsdatascience.com/eb767a59975b)\n",
    "- [Double Debiased Machine Learning (part 2)](https://towardsdatascience.com/bf990720a0b2)\n",
    "- [Understanding The Frisch-Waugh-Lovell Theorem](https://towardsdatascience.com/59f801eb3299)\n",
    "- [Understanding Contamination Bias](https://towardsdatascience.com/58b63d25d2ef)\n",
    "- [DAGs and Control Variables](https://towardsdatascience.com/b63dc69e3d8c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6666a96",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e271b8",
   "metadata": {},
   "source": [
    "You can find the original Jupyter Notebook here:\n",
    "\n",
    "https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/cuped.ipynb"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
